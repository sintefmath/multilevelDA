{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import datetime\n",
    "from IPython.display import display\n",
    "\n",
    "#For plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.rcParams[\"lines.color\"] = \"w\"\n",
    "plt.rcParams[\"text.color\"] = \"w\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"w\"\n",
    "plt.rcParams[\"xtick.color\"] = \"w\"\n",
    "plt.rcParams[\"ytick.color\"] = \"w\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Ocean-modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpuocean.utils import IPythonMagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basically, we only need the context and stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "gpu_stream = cuda.Stream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling GRF: FFT Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use GPU for sampling random numbers (first step of immense speed-up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 10#630\n",
    "ny = 5#315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpuocean.utils import Common\n",
    "\n",
    "random_numbers_host = np.zeros((nx,ny), dtype=np.float32, order='C')\n",
    "random_numbers = Common.CUDAArray2D(gpu_stream, ny, nx, 0, 0, random_numbers_host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycuda.curandom import XORWOWRandomNumberGenerator\n",
    "rng = XORWOWRandomNumberGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.fill_normal(random_numbers.data, stream=gpu_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = random_numbers.download(gpu_stream).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.hist(u.flatten(), bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one row of distance matrix needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist = np.zeros((nx*ny))\n",
    "for j in range(ny):\n",
    "    for i in range(nx):\n",
    "        dist[j*nx+i] = np.sqrt(i**2+j**2)\n",
    "        dist[j*nx+i] = min([np.sqrt(i**2+j**2),np.sqrt((i-nx)**2+j**2),np.sqrt(i**2+(j-ny)**2),np.sqrt((i-nx)**2+(j-ny)**2)]) # only periodic!! Otherwise complex fft values!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = 0.001\n",
    "corr = np.exp(-phi*dist**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_toepitz = np.reshape(corr, (ny, nx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cov_toepitz)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT on the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.fft.fft2(cov_toepitz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmf = np.real(np.fft.fft2(cov_toepitz))\n",
    "uif = np.fft.ifft2(u)\n",
    "xf = np.real(np.fft.fft2(np.sqrt(np.maximum(cmf,0))*uif))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(xf, origin=\"lower\", vmin=-1, vmax=1)\n",
    "plt.colorbar(shrink=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative code (same result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctf = np.fft.fft2(cov_toepitz)\n",
    "ctfsm = np.sqrt(np.maximum(0,ctf))\n",
    "uf = np.fft.fft2(u)\n",
    "grf = np.fft.ifft2(ctfsm*uf).real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(grf, vmin=-1, vmax=1)\n",
    "plt.colorbar(shrink=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT via skcuda (1D vs 2D?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pycuda.driver as cuda\n",
    "from pycuda.tools import make_default_context\n",
    "import pycuda.gpuarray as gpuarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skcuda.fft import fft, ifft, Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forums.developer.nvidia.com/t/how-to-apply-scikit-cuda-2d-fft-pycuda/33055\n",
    "\n",
    "data = np.random.randn(4,4)\n",
    "print(data)\n",
    "\n",
    "data_gpu = gpuarray.to_gpu(data.astype(np.float32))\n",
    "out_gpu = gpuarray.empty(data.shape, np.complex64)\n",
    "\n",
    "plan = Plan(data.shape, np.complex64, np.complex64)\n",
    "fft(data_gpu, out_gpu, plan)\n",
    "ifft(out_gpu, data_gpu, plan)\n",
    "\n",
    "print(\"It s a god damn shit!!! \")\n",
    "data_gpu.get()/np.product(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/lebedov/scikit-cuda/issues/253\n",
    "N = 4\n",
    "array = np.random.randint(255, size=(N, N)).astype(np.float32)\n",
    "print(array)\n",
    "array_gpu = gpuarray.to_gpu(array)\n",
    "ft = np.fft.fft2(array)\n",
    "print(ft)\n",
    "\n",
    "ft_gpu = gpuarray.empty((N//2+1, N//2+1), dtype=np.complex64)\n",
    "plan = Plan((N, N), np.float32, np.complex64)\n",
    "fft(array_gpu, ft_gpu, plan)\n",
    "print(ft_gpu.get())\n",
    "\n",
    "\n",
    "plan_inv = Plan((N, N), np.complex64, np.float32)\n",
    "ifft(ft_gpu, array_gpu, plan_inv)\n",
    "print(array)\n",
    "print(array_gpu.get()/np.product(array_gpu.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it 2D???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toep_gpu = gpuarray.to_gpu(cov_toepitz.astype(np.float32))\n",
    "cmf_gpu = gpuarray.empty(np.array(toep_gpu.shape)//2+1, np.complex64)\n",
    "plan = Plan(toep_gpu.shape, np.float32, np.complex64)\n",
    "fft(toep_gpu, cmf_gpu, plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmf, cmf_gpu.real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.idtools.com.au/gpu-accelerated-fft-compatible-with-numpy/\n",
    "u_gpu = gpuarray.to_gpu(u.astype(np.float32))\n",
    "uf_gpu = gpuarray.empty(np.array(u_gpu.shape)//2+1, np.complex64)\n",
    "fft(u_gpu, uf_gpu, plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf_gpu.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pycuda.cumath as cumath\n",
    "tmp_gpu = gpuarray.to_gpu((np.sqrt(np.maximum(cmf_gpu.get().real,0)) * uf_gpu.get()).astype(np.complex64))\n",
    "\n",
    "grf_gpu = gpuarray.empty(cov_toepitz.shape, np.float32)\n",
    "plan_inv = Plan(cov_toepitz.shape, np.complex64, np.float32)\n",
    "ifft(tmp_gpu, grf_gpu, plan_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grf_gpu.get()/nx/ny)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FFT via PyCuda Kernels (fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "from pycuda.compiler import SourceModule\n",
    "import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "a = numpy.random.randn(4,4)\n",
    "a = a.astype(numpy.float32)\n",
    "\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "\n",
    "mod = SourceModule(\"\"\"\n",
    "  __global__ void doublify(float *a)\n",
    "  {\n",
    "    int idx = threadIdx.x + threadIdx.y*4;\n",
    "    a[idx] *= 2;\n",
    "  }\n",
    "  \"\"\")\n",
    "#Allocate,generateandtransfer\n",
    "func = mod.get_function(\"doublify\")\n",
    "func(a_gpu, block=(4,4,1))\n",
    "\n",
    "a_doubled = numpy.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled,a_gpu)\n",
    "print(a, \"\\n\\n\", a_doubled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = gpu_ctx.get_kernel(\"fft.cu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = kernel.get_function(\"doublify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.prepare(\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func.prepared_async_call((4,4),(1,1,1),sim.gpu_stream, a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('gpuocean_opendrift')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3048633266a8aca5c85f16c1ee57ccad146141feb66febf24dcb8304467d1440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
