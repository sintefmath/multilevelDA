{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLDA experiment in Basin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets have matplotlib \"inline\"\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "#Import packages we need\n",
    "import numpy as np\n",
    "import datetime\n",
    "from IPython.display import display\n",
    "import copy\n",
    "\n",
    "#For plotting\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "plt.rcParams[\"lines.color\"] = \"w\"\n",
    "plt.rcParams[\"text.color\"] = \"w\"\n",
    "plt.rcParams[\"axes.labelcolor\"] = \"w\"\n",
    "plt.rcParams[\"xtick.color\"] = \"w\"\n",
    "plt.rcParams[\"ytick.color\"] = \"w\"\n",
    "\n",
    "plt.rcParams[\"image.origin\"] = \"lower\"\n",
    "\n",
    "import pycuda.driver as cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%dT%H_%M_%S\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU Ocean-modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpuocean.utils import IPythonMagic, Common\n",
    "from gpuocean.SWEsimulators import CDKLM16, ModelErrorKL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cuda_context_handler gpu_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_stream = cuda.Stream()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '../')))\n",
    "from utils.BasinInit import *\n",
    "from utils.BasinPlot import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_path = \"/home/florianb/havvarsel/multilevelDA/scripts/DataAssimilation/BasinTruth/2023-06-22T13_47_48\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = [6, 7, 8, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.BasinParameters import * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = []\n",
    "\n",
    "for l in ls:\n",
    "    lvl_grid_args = initGridSpecs(l)\n",
    "    args_list.append( {\n",
    "        \"nx\": lvl_grid_args[\"nx\"],\n",
    "        \"ny\": lvl_grid_args[\"ny\"],\n",
    "        \"dx\": lvl_grid_args[\"dx\"],\n",
    "        \"dy\": lvl_grid_args[\"dy\"],\n",
    "        \"gpu_ctx\": gpu_ctx,\n",
    "        \"gpu_stream\": gpu_stream,\n",
    "        \"boundary_conditions\": Common.BoundaryConditions(2,2,2,2)\n",
    "        } )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_args_list = []\n",
    "for l_idx in range(len(args_list)): \n",
    "    data_args_list.append( make_init_steady_state(args_list[l_idx], a=steady_state_bump_a, bump_fractal_dist=steady_state_bump_fractal_dist) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nes = [100, 50, 20, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpuocean.ensembles import MultiLevelOceanEnsemble\n",
    "MLOceanEnsemble = MultiLevelOceanEnsemble.MultiLevelOceanEnsembleCase(Nes, args_list, data_args_list, sample_args, make_sim,\n",
    "                            init_model_error_basis_args=init_model_error_basis_args, \n",
    "                            sim_model_error_basis_args=sim_model_error_basis_args, sim_model_error_timestep=sim_model_error_timestep)\n",
    "\n",
    "from gpuocean.dataassimilation import MLEnKFOcean\n",
    "MLEnKF = MLEnKFOcean.MLEnKFOcean(MLOceanEnsemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLOceanEnsemble.stepToObservation(900.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.BasinSL import *\n",
    "\n",
    "def g_functionalExp(SL_state):\n",
    "    \"\"\"\n",
    "    L_g functional as in notation of Kjetil's PhD thesis.\n",
    "    This should be the functional that is under investigation for the variance level plot\n",
    "\n",
    "    Input a ndarray of size (3, ny, nx, Ne)\n",
    "\n",
    "    Returns a ndarray of same size as SL_state (3, ny, nx, Ne)\n",
    "    \"\"\"\n",
    "    return SL_state\n",
    "\n",
    "def g_functionalVar(SL_state):\n",
    "    \"\"\"\n",
    "    L_g functional as in notation of Kjetil's PhD thesis.\n",
    "    This should be the functional that is under investigation for the variance level plot\n",
    "\n",
    "    Input a ndarray of size (3, ny, nx, Ne)\n",
    "\n",
    "    Returns a ndarray of same size as SL_state (3, ny, nx, Ne)\n",
    "    \"\"\"\n",
    "    return (SL_state - np.mean(SL_state, axis=-1)[:,:,:,np.newaxis])**2\n",
    "    \n",
    "def L2norm(field, lvl_grid_args):\n",
    "    \"\"\"\n",
    "    integral_D(f dx)\n",
    "    where D are uniform finite volumes\n",
    "\n",
    "    Input:\n",
    "    field           - ndarray of shape (3,ny,nx,..)\n",
    "    lvl_grid_args   - dict with nx, ny and dx, dy information\n",
    "\n",
    "    Output:\n",
    "    L2norm          - ndarray of shape (3,...)\n",
    "    \"\"\"\n",
    "    # assert field.shape[1:3] == (lvl_grid_args[\"ny\"], lvl_grid_args[\"nx\"]), \"field has wrong resolution\"\n",
    "    return np.sqrt(np.sum((field)**2 * lvl_grid_args[\"dx\"]*lvl_grid_args[\"dy\"], axis=(1,2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_state = MLOceanEnsemble.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = []\n",
    "for l_idx in range(len(ls)): \n",
    "    center_N = int(args_list[l_idx][\"nx\"]/8)\n",
    "    center_x = int(args_list[l_idx][\"nx\"]/2)\n",
    "    center_y = int(args_list[l_idx][\"ny\"]/2)\n",
    "    centers.append( np.s_[:, center_y-center_N:center_y+center_N, center_x-center_N:center_x+center_N,:] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_gExp = np.zeros((len(ls),3))\n",
    "prior_gVar = np.zeros((len(ls),3))\n",
    "prior_gExp_diff = np.zeros((len(ls),3))\n",
    "prior_gVar_diff = np.zeros((len(ls),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_idx in range(1,len(ls)):\n",
    "    prior_gExp[l_idx] = L2norm(np.var(g_functionalExp(ML_state[l_idx][0][centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "    prior_gVar[l_idx] = L2norm(np.var(g_functionalVar(ML_state[l_idx][0][centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "\n",
    "    prior_gExp_diff[l_idx] = L2norm(np.var(g_functionalExp(ML_state[l_idx][0][centers[l_idx]]) - g_functionalExp(ML_state[l_idx][1].repeat(2,1).repeat(2,2)[centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "    prior_gVar_diff[l_idx] = L2norm(np.var(g_functionalVar(ML_state[l_idx][0][centers[l_idx]]) - g_functionalVar(ML_state[l_idx][1].repeat(2,1).repeat(2,2)[centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.94273245e+00, 1.76760400e+07, 3.31826400e+07],\n",
       "        [2.73457074e+00, 5.47649000e+07, 6.86030400e+07],\n",
       "        [4.31430912e+00, 5.95542400e+07, 1.57749580e+07]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.88380387e-02, 1.92293719e+05, 7.28283562e+05],\n",
       "        [4.67220321e-03, 1.01467469e+05, 1.75830172e+05],\n",
       "        [1.17858569e-03, 2.19642422e+04, 1.78624922e+04]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_gVar, prior_gVar_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_path = \"/home/florianb/havvarsel/multilevelDA/scripts/DataAssimilation/BasinTruth/2023-06-22T13_47_48\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_GC = []\n",
    "for obs_x, obs_y in zip(obs_xs, obs_ys):\n",
    "    precomp_GC.append( MLEnKF.GCweights(obs_x, obs_y, r) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DA step\n",
    "true_eta, true_hu, true_hv = np.load(truth_path+\"/truth_\"+str(int(MLOceanEnsemble.t))+\".npy\")\n",
    "\n",
    "for h, [obs_x, obs_y] in enumerate(zip(obs_xs, obs_ys)):\n",
    "    Hx, Hy = MLOceanEnsemble.obsLoc2obsIdx(obs_x, obs_y)\n",
    "    obs = [true_eta[Hy,Hx], true_hu[Hy,Hx], true_hv[Hy,Hx]] + np.random.normal(0,R)\n",
    "    \n",
    "    prior = copy.deepcopy(MLOceanEnsemble.download())\n",
    "\n",
    "    ML_K = MLEnKF.assimilate(MLOceanEnsemble, obs, obs_x, obs_y, R, \n",
    "                            r=r, obs_var=slice(1,3), relax_factor=relax_factor, \n",
    "                            min_localisation_level=0,\n",
    "                            precomp_GC=precomp_GC[h])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_state = MLOceanEnsemble.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_gExp = np.zeros((len(ls),3))\n",
    "posterior_gVar = np.zeros((len(ls),3))\n",
    "posterior_gExp_diff = np.zeros((len(ls),3))\n",
    "posterior_gVar_diff = np.zeros((len(ls),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l_idx in range(1,len(ls)):\n",
    "    posterior_gExp[l_idx] = L2norm(np.var(g_functionalExp(ML_state[l_idx][0][centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "    posterior_gVar[l_idx] = L2norm(np.var(g_functionalVar(ML_state[l_idx][0][centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "    \n",
    "    posterior_gExp_diff[l_idx] = L2norm(np.var(g_functionalExp(ML_state[l_idx][0][centers[l_idx]]) - g_functionalExp(ML_state[l_idx][1].repeat(2,1).repeat(2,2)[centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n",
    "    posterior_gVar_diff[l_idx] = L2norm(np.var(g_functionalVar(ML_state[l_idx][0][centers[l_idx]]) - g_functionalVar(ML_state[l_idx][1].repeat(2,1).repeat(2,2)[centers[l_idx]]),ddof=1, axis=-1), args_list[l_idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.04965389e+00, 7.73194650e+06, 2.25394180e+07],\n",
       "        [1.86873877e+00, 3.18739100e+07, 4.41292280e+07],\n",
       "        [1.76371062e+00, 3.15729640e+07, 1.07291390e+07]]),\n",
       " array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.15062678e-02, 9.50481094e+04, 5.16164938e+05],\n",
       "        [2.55720713e-03, 5.27026484e+04, 1.12557609e+05],\n",
       "        [2.19191556e-04, 5.49662842e+03, 5.47383398e+03]]))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_gVar, posterior_gVar_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianb/miniconda3/envs/gpuocean_opendrift/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan],\n",
       "       [0.54029771, 0.43742527, 0.67925331],\n",
       "       [0.68337554, 0.58201348, 0.6432547 ],\n",
       "       [0.40880488, 0.53015476, 0.68013741]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_gVar/prior_gVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianb/miniconda3/envs/gpuocean_opendrift/lib/python3.7/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[       nan,        nan,        nan],\n",
       "       [0.61079967, 0.49428608, 0.70874171],\n",
       "       [0.54732361, 0.51940439, 0.64014957],\n",
       "       [0.18597846, 0.2502535 , 0.3064429 ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_gVar_diff/prior_gVar_diff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "3048633266a8aca5c85f16c1ee57ccad146141feb66febf24dcb8304467d1440"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
